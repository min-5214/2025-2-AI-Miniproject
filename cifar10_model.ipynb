{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54d9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used anaconda 3.12.3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from model import SimpleCNN, train, test\n",
    "from customCIFAR10 import CustomCIFAR10\n",
    "from confMatrix import plot_confusion_matrix\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2414c",
   "metadata": {},
   "source": [
    "LOADING DATASET\n",
    "\n",
    "    First prepare our data by importing the CIFAR-10 database as both the traning and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73553910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     21\u001b[39m test_loader = DataLoader(testset, batch_size=\u001b[32m100\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m2\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 6. Experiment Configurations\u001b[39;00m\n\u001b[32m     24\u001b[39m experiments = {\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBaseline\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: trainset, \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m: transform},\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRandom Label Shuffle\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: CustomCIFAR10(trainset, noise_type=\u001b[33m\"\u001b[39m\u001b[33mrandom_shuffle\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m: transform},\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLabel Noise 20\u001b[39m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mCustomCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel_noise\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m: transform},\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLabel Noise 40\u001b[39m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: CustomCIFAR10(trainset, noise_type=\u001b[33m\"\u001b[39m\u001b[33mlabel_noise\u001b[39m\u001b[33m\"\u001b[39m, noise_rate=\u001b[32m0.4\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m: transform},\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLabel Noise 60\u001b[39m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: CustomCIFAR10(trainset, noise_type=\u001b[33m\"\u001b[39m\u001b[33mlabel_noise\u001b[39m\u001b[33m\"\u001b[39m, noise_rate=\u001b[32m0.6\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m: transform},\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLabel Noise 80\u001b[39m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: CustomCIFAR10(trainset, noise_type=\u001b[33m\"\u001b[39m\u001b[33mlabel_noise\u001b[39m\u001b[33m\"\u001b[39m, noise_rate=\u001b[32m0.8\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m: transform},\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCropped Images\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: datasets.CIFAR10(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform_crop)},\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFlipped Images\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: datasets.CIFAR10(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform_flip)},\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBlurred Images\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m: datasets.CIFAR10(root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, download=\u001b[38;5;28;01mTrue\u001b[39;00m, transform=transform_blur)}\n\u001b[32m     34\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5214m\\OneDrive\\Documents\\Desktop\\Uni\\3-2\\AIProj\\2025-2-AI-Miniproject\\customCIFAR10.py:9\u001b[39m, in \u001b[36mCustomCIFAR10.__init__\u001b[39m\u001b[34m(self, dataset, noise_type, noise_rate)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.noise_type = noise_type\n\u001b[32m      8\u001b[39m \u001b[38;5;28mself\u001b[39m.noise_rate = noise_rate\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mself\u001b[39m.labels = \u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m noise_type == \u001b[33m\"\u001b[39m\u001b[33mrandom_shuffle\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     12\u001b[39m     random.shuffle(\u001b[38;5;28mself\u001b[39m.labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5214m\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[39m, in \u001b[36mCIFAR10.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    116\u001b[39m img = Image.fromarray(img)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    122\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5214m\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5214m\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5214m\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pic.mode == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    171\u001b[39m     img = \u001b[32m255\u001b[39m * img\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m img = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[32m    174\u001b[39m img = img.permute((\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).contiguous()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "transform_crop = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "transform_flip = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),     \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "transform_blur = transforms.Compose([\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# 6. Experiment Configurations\n",
    "experiments = {\n",
    "    \"Baseline\": {\"dataset\": trainset, \"transform\": transform},\n",
    "    \"Random Label Shuffle\": {\"dataset\": CustomCIFAR10(trainset, noise_type=\"random_shuffle\"), \"transform\": transform},\n",
    "    \"Label Noise 20%\": {\"dataset\": CustomCIFAR10(trainset, noise_type=\"label_noise\", noise_rate=0.2), \"transform\": transform},\n",
    "    \"Label Noise 40%\": {\"dataset\": CustomCIFAR10(trainset, noise_type=\"label_noise\", noise_rate=0.4), \"transform\": transform},\n",
    "    \"Label Noise 60%\": {\"dataset\": CustomCIFAR10(trainset, noise_type=\"label_noise\", noise_rate=0.6), \"transform\": transform},\n",
    "    \"Label Noise 80%\": {\"dataset\": CustomCIFAR10(trainset, noise_type=\"label_noise\", noise_rate=0.8), \"transform\": transform},\n",
    "    \"Cropped Images\": {\"dataset\": datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_crop)},\n",
    "    \"Flipped Images\": {\"dataset\": datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_flip)},\n",
    "    \"Blurred Images\": {\"dataset\": datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_blur)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d181272",
   "metadata": {},
   "source": [
    "2. RUNNING TESTS\n",
    "\n",
    "    We will then use our CNN model defined in model.py where we train the model, test its accuracy then reiterate for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment: Baseline\n",
      "Test Accuracy: 72.72%\n",
      "\n",
      "Running experiment: Random Label Shuffle\n",
      "Test Accuracy: 11.54%\n",
      "\n",
      "Running experiment: Label Noise\n",
      "Test Accuracy: 66.79%\n",
      "\n",
      "Running experiment: Cropped Images\n",
      "Test Accuracy: 71.95%\n",
      "\n",
      "Running experiment: Flipped Images\n",
      "Test Accuracy: 71.86%\n",
      "\n",
      "Running experiment: Blurred Images\n",
      "Test Accuracy: 71.16%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results = {}\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for exp_name, config in experiments.items():\n",
    "    print(f\"\\nRunning experiment: {exp_name}\")\n",
    "    model = SimpleCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loader = DataLoader(config[\"dataset\"], batch_size=100, shuffle=True, num_workers=2)\n",
    "    train(model, device, train_loader, optimizer, criterion, num_epochs=5)\n",
    "    \n",
    "    accuracy, class_accuracies, y_true, y_pred = test(model, device, test_loader)\n",
    "    results[exp_name] = {\"accuracy\": accuracy, \"class_accuracies\": class_accuracies}\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names, exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d6391",
   "metadata": {},
   "source": [
    "3. VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-wise Accuracy Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "x = np.arange(len(class_names)) \n",
    "width = 0.13\n",
    "excluded = {\"Label Noise 40%\", \"Label Noise 60%\", \"Label Noise 80%\"}\n",
    "included_experiments = [exp_name for exp_name in results if exp_name not in excluded]\n",
    "for i, exp_name in enumerate(included_experiments):\n",
    "    result = results[exp_name]\n",
    "    plt.bar(x + i*width, result[\"class_accuracies\"], width, label=exp_name)\n",
    "\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Accuracy for Selected Experiments')\n",
    "plt.xticks(x + (width * (len(included_experiments) - 1) / 2), class_names, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_accuracies_filtered.png')\n",
    "plt.close()\n",
    "\n",
    "# Overall Accuracy Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "excluded = {\"Label Noise 40%\", \"Label Noise 60%\", \"Label Noise 80%\"}\n",
    "exp_names = [exp_name for exp_name in results if exp_name not in excluded]\n",
    "accuracies = [results[exp][\"accuracy\"] for exp in exp_names]\n",
    "plt.bar(exp_names, accuracies)\n",
    "plt.xlabel('Experiment')\n",
    "plt.ylabel('Overall Accuracy (%)')\n",
    "plt.title('Overall Accuracy for Different Experiments')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('overall_accuracies.png')\n",
    "plt.close()\n",
    "\n",
    "# Label noise level accuracy plot\n",
    "noise_labels = [\n",
    "    \"Baseline\",\n",
    "    \"Label Noise 20%\",\n",
    "    \"Label Noise 40%\",\n",
    "    \"Label Noise 60%\",\n",
    "    \"Label Noise 80%\",\n",
    "    \"Random Label Shuffle\"\n",
    "]\n",
    "x = [0, 20, 40, 60, 80, 100]\n",
    "y = [results[label][\"accuracy\"] for label in noise_labels]\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(x, y, marker='o', linestyle='-', color='tab:blue')\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Label Noise (%)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy vs. Label Noise Level\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"accuracy_vs_label_noise.png\")\n",
    "plt.close()\n",
    "\n",
    "# 9. Save Results to Text File\n",
    "with open('experiment_results.txt', 'w') as f:\n",
    "    for exp_name, result in results.items():\n",
    "        f.write(f\"\\nExperiment: {exp_name}\\n\")\n",
    "        f.write(f\"Overall Accuracy: {result['accuracy']:.2f}%\\n\")\n",
    "        f.write(\"Class-wise Accuracies:\\n\")\n",
    "        for cls, acc in zip(class_names, result['class_accuracies']):\n",
    "            f.write(f\"  {cls}: {acc:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
