{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54d9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used anaconda 3.12.3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from model import SimpleCNN, train, test\n",
    "from customCIFAR10 import CustomCIFAR10\n",
    "from confMatrix import plot_confusion_matrix\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2414c",
   "metadata": {},
   "source": [
    "1. LOADING DATASET\n",
    "\n",
    "    First prepare our data by importing the CIFAR-10 database as both the traning and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73553910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "transform_crop = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "transform_flip = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor(),     \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "transform_blur = transforms.Compose([\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# 6. Experiment Configurations\n",
    "experiments = {\n",
    "    \"Baseline\": {\"dataset\": trainset, \"transform\": transform},\n",
    "    \"Random Label Shuffle\": {\"dataset\": CustomCIFAR10(trainset, noise_type=\"random_shuffle\"), \"transform\": transform},\n",
    "    \"Label Noise\": {\"dataset\": CustomCIFAR10(trainset, noise_type=\"label_noise\", noise_rate=0.2), \"transform\": transform},\n",
    "    \"Cropped Images\": {\"dataset\": datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_crop)},\n",
    "    \"Flipped Images\": {\"dataset\": datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_flip)},\n",
    "    \"Blurred Images\": {\"dataset\": datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_blur)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d181272",
   "metadata": {},
   "source": [
    "We will then use our CNN model defined in model.py where we train the model, test its accuracy then reiterate for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ce57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running experiment: Baseline\n",
      "Test Accuracy: 72.72%\n",
      "\n",
      "Running experiment: Random Label Shuffle\n",
      "Test Accuracy: 11.54%\n",
      "\n",
      "Running experiment: Label Noise\n",
      "Test Accuracy: 66.79%\n",
      "\n",
      "Running experiment: Cropped Images\n",
      "Test Accuracy: 71.95%\n",
      "\n",
      "Running experiment: Flipped Images\n",
      "Test Accuracy: 71.86%\n",
      "\n",
      "Running experiment: Blurred Images\n",
      "Test Accuracy: 71.16%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results = {}\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "for exp_name, config in experiments.items():\n",
    "    print(f\"\\nRunning experiment: {exp_name}\")\n",
    "    model = SimpleCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loader = DataLoader(config[\"dataset\"], batch_size=100, shuffle=True, num_workers=2)\n",
    "    train(model, device, train_loader, optimizer, criterion, num_epochs=5)\n",
    "    \n",
    "    accuracy, class_accuracies, y_true, y_pred = test(model, device, test_loader)\n",
    "    results[exp_name] = {\"accuracy\": accuracy, \"class_accuracies\": class_accuracies}\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    plot_confusion_matrix(y_true, y_pred, class_names, exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d6391",
   "metadata": {},
   "source": [
    "Visualising the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6c7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-wise Accuracy Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "x = np.arange(len(class_names)) \n",
    "width = 0.13\n",
    "\n",
    "# Plot bars for each experiment\n",
    "for i, (exp_name, result) in enumerate(results.items()):\n",
    "    plt.bar(x + i*width, result[\"class_accuracies\"], width, label=exp_name)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Accuracy for Different Experiments')\n",
    "plt.xticks(x + (width * 2.5), class_names, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_accuracies.png')\n",
    "plt.close()\n",
    "\n",
    "# Overall Accuracy Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "exp_names = list(results.keys())\n",
    "accuracies = [results[exp][\"accuracy\"] for exp in exp_names]\n",
    "plt.bar(exp_names, accuracies)\n",
    "plt.xlabel('Experiment')\n",
    "plt.ylabel('Overall Accuracy (%)')\n",
    "plt.title('Overall Accuracy for Different Experiments')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('overall_accuracies.png')\n",
    "plt.close()\n",
    "\n",
    "# 9. Save Results to Text File\n",
    "with open('experiment_results.txt', 'w') as f:\n",
    "    for exp_name, result in results.items():\n",
    "        f.write(f\"\\nExperiment: {exp_name}\\n\")\n",
    "        f.write(f\"Overall Accuracy: {result['accuracy']:.2f}%\\n\")\n",
    "        f.write(\"Class-wise Accuracies:\\n\")\n",
    "        for cls, acc in zip(class_names, result['class_accuracies']):\n",
    "            f.write(f\"  {cls}: {acc:.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
